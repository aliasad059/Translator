{"cells":[{"attachments":{},"cell_type":"markdown","id":"f7171f8c","metadata":{},"source":["# Translator\n","Here we implement 3+1 encoder-decoder models to understand neural machine translation\n","- 0: Reverse sentence encoder-decoder model(No Learning!)\n","- 1: Encoder-decoder model with the simplest architecture\n","- 2: Teacher forcing encoder-decoder model\n","- 3: Above models plus embedding layer instead of one-hot encoding"]},{"attachments":{},"cell_type":"markdown","id":"bbff2d27","metadata":{},"source":["![Alt text](images/12_encoder_decoder_2.png)"]},{"cell_type":"code","execution_count":24,"id":"ba55b592-a83a-4e48-ad5b-5836c3b914aa","metadata":{"executionCancelledAt":null,"executionTime":1644,"lastExecutedAt":1693990471455,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Write and run code here\nfrom tensorflow.keras.utils import to_categorical\nimport numpy as np\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import Input, RepeatVector\nfrom tensorflow.keras.models import Model","outputsMetadata":{"0":{"height":115,"type":"stream"}}},"outputs":[],"source":["# Import libraries\n","\n","import numpy as np\n","import tensorflow.keras as keras\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical"]},{"attachments":{},"cell_type":"markdown","id":"48248776","metadata":{},"source":["## 1. Basics"]},{"attachments":{},"cell_type":"markdown","id":"3dae4ecb-a97d-4305-b187-d7af4176ae02","metadata":{},"source":["### 1.1. Onehot encoding"]},{"cell_type":"code","execution_count":2,"id":"470df5ca-d5b8-4ba7-9279-ef7cd35c6013","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1693990471511,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define a sample word2index dictionary\nword2index = {'I': 0, 'like': 1, 'cats': 2}\n\n# Create a list of words and convert them to indices\nwords = ['I', 'like', 'cats']\nword_ids = [word2index[w] for w in words]\nword_ids"},"outputs":[{"data":{"text/plain":["[0, 1, 2]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Define a sample word2index dictionary\n","word2index = {'I': 0, 'like': 1, 'cats': 2}\n","\n","# Create a list of words and convert them to indices\n","words = ['I', 'like', 'cats']\n","word_ids = [word2index[w] for w in words]\n","word_ids"]},{"cell_type":"code","execution_count":3,"id":"58961ffa-9e2e-4303-ab77-d943d9bc36e0","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1693990471564,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def compute_onehot_length(words, word2index):\n  # Create word IDs for words\n  word_ids = [word2index[w] for w in words]\n  # Convert word IDs to onehot vectors\n  onehot = to_categorical(word_ids)\n  # Return the length of a single one-hot vector\n  return onehot.shape[1]\n\nword2index = {\"He\":0, \"drank\": 1, \"milk\": 2, \"like\": 3, \"cats\": 4, \"We\": 5, \"dogs\": 6, \"hates\": 7, \"rabbits\": 8, \"I\": 9}\n# Compute and print onehot length of a list of words\nprint(compute_onehot_length(['He','drank','milk'], word2index))\n\nwords_1 = [\"I\", \"like\", \"cats\", \"We\", \"like\", \"dogs\", \"He\", \"hates\", \"rabbits\"]\n# Call compute_onehot_length on words_1\nlength_1 = compute_onehot_length(words_1, word2index)\n\nwords_2 = [\"We\", \"like\", \"dogs\", \"We\", \"like\", \"cats\"]\n# Call compute_onehot_length on words_2\nlength_2 = compute_onehot_length(words_2, word2index)\n\n# Print length_1 and length_2\nprint(\"length_1 =>\", length_1, \" and length_2 => \", length_2)","outputsMetadata":{"0":{"height":56,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["length_1 => 10  and length_2 =>  7\n"]}],"source":["def words2onehot(word_list, word2index):\n","  # Convert words to word IDs\n","  word_ids = [word2index[w] for w in word_list]\n","  # Convert word IDs to onehot vectors and return the onehot array\n","  # onehot = to_categorical(word_ids, num_classes=3)\n","  onehot = to_categorical(word_ids)\n","  return onehot\n","\n","word2index = {\"He\":0, \"drank\": 1, \"milk\": 2, \"like\": 3, \"cats\": 4, \"We\": 5, \"dogs\": 6, \"hates\": 7, \"rabbits\": 8, \"I\": 9}\n","\n","words_1 = [\"I\", \"like\", \"cats\", \"We\", \"like\", \"dogs\", \"He\", \"hates\", \"rabbits\"]\n","# Call words2onehot on words_1\n","length_1 = words2onehot(words_1, word2index).shape[1]\n","\n","words_2 = [\"We\", \"like\", \"dogs\", \"We\", \"like\", \"cats\"]\n","# Call words2onehot on words_2\n","length_2 = words2onehot(words_2, word2index).shape[1]\n","\n","# Print length_1 and length_2\n","print(\"length_1 =>\", length_1, \" and length_2 => \", length_2)"]},{"attachments":{},"cell_type":"markdown","id":"764ce367-093f-409b-aebc-06ff3ae78f80","metadata":{},"source":["### 1.2. Text Reversing Model\n","a simple encoder-decoder model that simply do nothing but reversing the input sentence"]},{"cell_type":"code","execution_count":4,"id":"fc6c67e4-603d-49fc-a9ab-eff2dac09e57","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1693990471612,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def words2onehot(word_list, word2index):\n  # Convert words to word IDs\n  word_ids = [word2index[w] for w in word_list]\n  # Convert word IDs to onehot vectors and return the onehot array\n  onehot = to_categorical(word_ids, num_classes=3)\n  return onehot\n\nwords = [\"I\", \"like\", \"cats\"]\nword2index = {\"I\":0, \"like\": 1, \"cats\":2}\nindex2word = {0:'I', 1: 'like', 2:'cats'}\n# Convert words to onehot vectors using words2onehot\nonehot = words2onehot(words, word2index)\n# Print the result as (<word>, <onehot>) tuples\nprint([(w,ohe.tolist()) for w,ohe in zip(words, onehot)])","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["[('I', [1.0, 0.0, 0.0]), ('like', [0.0, 1.0, 0.0]), ('cats', [0.0, 0.0, 1.0])]\n"]}],"source":["word2index = {\"I\":0, \"like\": 1, \"cats\":2}\n","words = list(word2index.keys())\n","index2word = {v:k for k,v in word2index.items()}\n","\n","# Convert words to onehot vectors using words2onehot\n","onehot = words2onehot(words, word2index)\n","\n","print([(w,ohe.tolist()) for w,ohe in zip(words, onehot)])"]},{"cell_type":"code","execution_count":5,"id":"f55a9045-9708-4d89-99e5-534984b35200","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1693990471659,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def encoder(onehot):\n  # Get word IDs from onehot vectors and return the IDs\n  word_ids = np.argmax(onehot, axis=1)\n  return word_ids\n\nonehot = words2onehot(words, word2index)\n# Get the context vector by using the encoder function\ncontext = encoder(onehot)\nprint(context)","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1 2]\n"]}],"source":["def encoder(onehot):\n","  # Get word IDs from onehot vectors and return the IDs\n","  word_ids = np.argmax(onehot, axis=1)\n","  return word_ids\n","\n","onehot = words2onehot(words, word2index)\n","# Get the context vector by using the encoder function\n","context = encoder(onehot)\n","print(context)"]},{"cell_type":"code","execution_count":6,"id":"200ec2c4-b895-449a-8376-776a85716ca4","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1693990471715,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the onehot2words function that returns words for a set of onehot vectors\ndef onehot2words(onehot, index2word):\n  ids = np.argmax(onehot, axis=1)\n  res = [index2word[id] for id in ids]\n  return res\n# Define the decoder function that returns reversed onehot vectors\ndef decoder(context_vector):\n  word_ids_rev = context_vector[::-1]\n  onehot_rev = to_categorical(word_ids_rev, num_classes=3)\n  return onehot_rev\n# Convert context to reversed onehot vectors using decoder\nonehot_rev = decoder(context)\n# Get the reversed words using the onehot2words function\nreversed_words = onehot2words(onehot_rev, index2word)\nprint(reversed_words)","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["['cats', 'like', 'I']\n"]}],"source":["# Define the onehot2words function that returns words for a set of onehot vectors\n","def onehot2words(onehot, index2word):\n","  ids = np.argmax(onehot, axis=1)\n","  res = [index2word[id] for id in ids]\n","  return res\n","\n","# Define the decoder function that returns reversed onehot vectors\n","def decoder(context_vector):\n","  word_ids_rev = context_vector[::-1]\n","  onehot_rev = to_categorical(word_ids_rev, num_classes=3)\n","  return onehot_rev"]},{"cell_type":"code","execution_count":null,"id":"9dbc488b","metadata":{},"outputs":[],"source":["# Convert context to reversed onehot vectors using decoder\n","onehot_rev = decoder(context)\n","# Get the reversed words using the onehot2words function\n","reversed_words = onehot2words(onehot_rev, index2word)\n","\n","print(reversed_words)"]},{"attachments":{},"cell_type":"markdown","id":"73d6789f","metadata":{},"source":["## 2. Neural Machine Translation Model(V1)"]},{"attachments":{},"cell_type":"markdown","id":"0ac496f2","metadata":{},"source":["![Alt text](images/ch28_full_model.png)"]},{"attachments":{},"cell_type":"markdown","id":"e0665f55-ab8e-4248-aef0-a8b3852317cc","metadata":{},"source":["### 2.1. Load Data"]},{"cell_type":"code","execution_count":7,"id":"f3676435-103f-4fb8-ab6c-423fe7789867","metadata":{"executionCancelledAt":null,"executionTime":92,"lastExecutedAt":1693990471807,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def load_sentences(file_path):\n    with open(file_path, 'r', encoding='utf-8') as file:\n        sentences = file.readlines()\n    sentences = [sentence.strip() for sentence in sentences]\n    return sentences\n\nen_text = load_sentences('datasets/vocab_en.txt')\nfr_text = load_sentences('datasets/vocab_fr.txt')","outputsMetadata":{"0":{"height":56,"type":"stream"}}},"outputs":[],"source":["def load_sentences(file_path):\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        sentences = file.readlines()\n","    sentences = [sentence.strip() for sentence in sentences]\n","    return sentences\n","\n","en_text = load_sentences('datasets/en2fr/vocab_en.txt')\n","fr_text = load_sentences('datasets/en2fr/vocab_fr.txt')\n","\n","# en_text = load_sentences('datasets/en2fa/ak-test-1k.en')\n","# fr_text = load_sentences('datasets/en2fa/ak-test-1k.fa')"]},{"cell_type":"code","execution_count":8,"id":"d1437fae-97cb-4e11-93e7-bdcdfde79961","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1693990471856,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Iterate through the first 5 English and French sentences in the dataset\nfor en_sent, fr_sent in zip(en_text[:2], fr_text[:2]):\n  print(\"English: \", en_sent)\n  print(\"\\tFrench: \", fr_sent)","outputsMetadata":{"0":{"height":134,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["**************************************************\n","English:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n","French:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n","**************************************************\n","English:  the united states is usually chilly during july , and it is usually freezing in november .\n","French:  les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n"]}],"source":["# Iterate through the first 5 English and French sentences in the dataset\n","for en_sent, fr_sent in zip(en_text[:2], fr_text[:2]):\n","  print('*'*50)\n","  print(\"English: \", en_sent)\n","  print(\"French: \", fr_sent)"]},{"cell_type":"code","execution_count":9,"id":"8f0b2165-1100-4311-b948-62f8cc96be4a","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":56,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["(English) Mean and Max sentence length:  13.225678224285508 17\n","(English) Vocabulary size:  228\n"]}],"source":["# Compute length of sentences\n","sent_lengths = [len(en_sent.split(' ')) for en_sent in en_text]\n","print('(English) Mean and Max sentence length: ', np.mean(sent_lengths), np.max(sent_lengths))\n","\n","all_words = []\n","for sent in en_text:\n","  all_words.extend(sent.split(' '))\n","\n","# Compute the length of the set containing all_words\n","vocab_size = len(set(all_words))\n","print(\"(English) Vocabulary size: \", vocab_size)"]},{"cell_type":"code","execution_count":10,"id":"df3ce1ad-798b-436c-b72d-d142f0d285df","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":56,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["(French) Mean and Max sentence length:  14.226730015958218 23\n","(French) Vocabulary size:  356\n"]}],"source":["# Compute length of sentences\n","sent_lengths = [len(fr_sent.split(' ')) for fr_sent in fr_text]\n","print('(French) Mean and Max sentence length: ', np.mean(sent_lengths), np.max(sent_lengths))\n","\n","all_words = []\n","for sent in fr_text:\n","  all_words.extend(sent.split(' '))\n","  \n","# Compute the length of the set containing all_words\n","vocab_size = len(set(all_words))\n","print(\"(French) Vocabulary size: \", vocab_size)"]},{"attachments":{},"cell_type":"markdown","id":"0f6045e4","metadata":{},"source":["### 2.2. Fit Tokenizers"]},{"cell_type":"code","execution_count":null,"id":"575e014c","metadata":{},"outputs":[],"source":["# set some parameters\n","en_len = 25\n","fr_len = 25\n","\n","en_vocab = 250\n","fr_vocab = 250"]},{"cell_type":"code","execution_count":null,"id":"718bfc0d","metadata":{},"outputs":[],"source":["en_tok = Tokenizer(num_words=en_vocab, oov_token='UNK')\n","\n","# Fit the tokenizer on en_text\n","en_tok.fit_on_texts(en_text)\n","\n","# Convert the sentence to a word ID sequence\n","seq_new = en_tok.texts_to_sequences(['she likes grapefruit , peaches , and lemons .'])\n","print('Word ID sequence (with UNK): ', seq_new)\n","print('The ID 1 represents the word: ', en_tok.index_word[1])"]},{"cell_type":"code","execution_count":null,"id":"bd69387a","metadata":{},"outputs":[],"source":["fr_text = [\" \".join(['sos', sent, 'eos']) for sent in fr_text]\n","fr_tok = Tokenizer(num_words=fr_vocab, oov_token='UNK')\n","\n","# Fit the tokenizer on fr_text\n","fr_tok.fit_on_texts(fr_text)\n","\n","# Convert the sentence to a word ID sequence\n","seq_new = fr_tok.texts_to_sequences(['sos les états-unis est généralement froid en juillet . eos'])\n","print('Word ID sequence (with UNK): ', seq_new)\n","print('The ID 1 represents the word: ', fr_tok.index_word[1])"]},{"attachments":{},"cell_type":"markdown","id":"d717eaa9-5d6d-4aae-b32d-3adcbb28a159","metadata":{},"source":["### 2.3. Encoder"]},{"cell_type":"code","execution_count":11,"id":"113f7c24-4eef-402b-9f6e-d46be8e9df18","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":310,"type":"stream"},"1":{"height":251,"type":"stream"}}},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-09-08 13:34:21.482783: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 25, 250)]         0         \n","                                                                 \n"," gru (GRU)                   [(None, 48),              43200     \n","                              (None, 48)]                        \n","                                                                 \n","=================================================================\n","Total params: 43200 (168.75 KB)\n","Trainable params: 43200 (168.75 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}],"source":["hsize = 48\n","\n","# Input layer\n","en_inputs = keras.layers.Input(shape=(en_len, en_vocab))\n","\n","# GRU layer which returns the state and get the output and state from the GRU\n","en_out, en_state = keras.layers.GRU(hsize, return_state=True)(en_inputs)\n","\n","encoder = keras.models.Model(inputs=en_inputs, outputs=en_state)\n","print(encoder.summary())"]},{"attachments":{},"cell_type":"markdown","id":"e4fb437f","metadata":{},"source":["### 2.4. Decoder"]},{"cell_type":"code","execution_count":12,"id":"2d62830b-f964-40d9-8a70-31ea21e7d61f","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":388,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 25, 250)]            0         []                            \n","                                                                                                  \n"," gru (GRU)                   [(None, 48),                 43200     ['input_1[0][0]']             \n","                              (None, 48)]                                                         \n","                                                                                                  \n"," repeat_vector (RepeatVecto  (None, 25, 48)               0         ['gru[0][1]']                 \n"," r)                                                                                               \n","                                                                                                  \n"," gru_1 (GRU)                 (None, 25, 48)               14112     ['repeat_vector[0][0]',       \n","                                                                     'gru[0][1]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 57312 (223.88 KB)\n","Trainable params: 57312 (223.88 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["de_inputs = keras.layers.RepeatVector(fr_len)(en_state) \n","\n","decoder_gru = keras.layers.GRU(hsize, return_sequences=True)\n","gru_outputs = decoder_gru(de_inputs, initial_state=en_state)\n","\n","# Define a softmax dense layer that has fr_vocab outputs and wrap the dense layer in a TimeDistributed layer\n","de_dense = keras.layers.Dense(fr_vocab, activation='softmax')\n","de_dense_time = keras.layers.TimeDistributed(de_dense)\n","\n","# Get the final prediction of the model\n","de_pred = de_dense_time(gru_outputs)\n","print(\"Prediction shape: \", de_pred.shape)"]},{"attachments":{},"cell_type":"markdown","id":"91691b23","metadata":{},"source":["### 2.5. Encode-Decoder Model"]},{"cell_type":"code","execution_count":14,"id":"33e9603c-8320-480d-806c-6e9ba5bc6126","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":446,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 25, 250)]            0         []                            \n","                                                                                                  \n"," gru (GRU)                   [(None, 48),                 43200     ['input_1[0][0]']             \n","                              (None, 48)]                                                         \n","                                                                                                  \n"," repeat_vector (RepeatVecto  (None, 25, 48)               0         ['gru[0][1]']                 \n"," r)                                                                                               \n","                                                                                                  \n"," gru_1 (GRU)                 (None, 25, 48)               14112     ['repeat_vector[0][0]',       \n","                                                                     'gru[0][1]']                 \n","                                                                                                  \n"," time_distributed (TimeDist  (None, 25, 250)              12250     ['gru_1[0][0]']               \n"," ributed)                                                                                         \n","                                                                                                  \n","==================================================================================================\n","Total params: 69562 (271.73 KB)\n","Trainable params: 69562 (271.73 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["# Define a model with encoder input and decoder output\n","nmt = Model(inputs=en_inputs, outputs=de_pred)\n","\n","# Compile the model with an optimizer and a loss\n","nmt.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n","\n","# View the summary of the model \n","nmt.summary()"]},{"cell_type":"code","execution_count":19,"id":"210d7007-89e7-4063-92ac-cd4cdabdfe95","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1693990478844,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"sentences = [\"california is never rainy during july .\"]\n# Add new keyword parameter reverse which defaults to False\ndef sents2seqs(input_type, sentences, onehot=False, pad_type='post', reverse=False):     \n    encoded_text = en_tok.texts_to_sequences(sentences)\n    preproc_text = pad_sequences(encoded_text, padding=pad_type, truncating='post', maxlen=en_len)\n    if reverse:\n      # Reverse the text using numpy axis reversing\n      preproc_text = preproc_text[:, ::-1]\n    if onehot:\n        preproc_text = to_categorical(preproc_text, num_classes=en_vocab)\n    return preproc_text\n# Call sents2seqs to get the padded and reversed sequence of IDs\npad_seq = sents2seqs('source', sentences, reverse=True)\nrev_sent = [en_tok.index_word[wid] for wid in pad_seq[0][-6:]] \nprint('\\tReversed: ',' '.join(rev_sent))","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["\tReversed:  july during rainy never is california\n"]}],"source":["def sents2seqs(input_type, sentences, onehot=False, pad_type='post', reverse=False):     \n","    if input_type == 'source':\n","      encoded_text = en_tok.texts_to_sequences(sentences)\n","    elif input_type == 'target':\n","      encoded_text = fr_tok.texts_to_sequences(sentences)\n","       \n","    preproc_text = pad_sequences(encoded_text, padding=pad_type, truncating='post', maxlen=en_len)\n","\n","    if reverse:\n","      preproc_text = preproc_text[:, ::-1]\n","\n","    if onehot:\n","        preproc_text = to_categorical(preproc_text, num_classes=en_vocab)\n","\n","    return preproc_text"]},{"cell_type":"code","execution_count":null,"id":"0df7fd4d","metadata":{},"outputs":[],"source":["sentences = [\"california is never rainy during july .\"]\n","\n","pad_seq = sents2seqs('source', sentences, reverse=True, onehot=False)\n","rev_sent = [en_tok.index_word[wid] for wid in pad_seq[0] if wid != 0] \n","print('\\tReversed: ',' '.join(rev_sent))"]},{"cell_type":"code","execution_count":20,"id":"c3fba8e7-0927-4ce7-98f2-ee5725563459","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1693990478891,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"sentence = 'she likes grapefruit , peaches , and lemons .'  \n# Convert a sentence to sequence by pre-padding the sentence\npad_seq = sents2seqs('source', [sentence], pad_type='pre')\npad_seq"},"outputs":[{"data":{"text/plain":["array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0, 28, 71, 29, 77,  8, 73]], dtype=int32)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["sentences = ['she likes grapefruit , peaches , and lemons .'  ]\n","\n","pad_seq = sents2seqs('source', sentences, pad_type='pre')\n","pad_seq"]},{"attachments":{},"cell_type":"markdown","id":"13a04bbf","metadata":{},"source":["### 2.6. Train and Evaluate NMT"]},{"cell_type":"code","execution_count":21,"id":"0052c7fc-6010-4689-8d5f-344fcc96d3c1","metadata":{"executionCancelledAt":null,"executionTime":57,"lastExecutedAt":1693990484572,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"train_size, valid_size = 800, 200\n# Define a sequence of indices from 0 to len(en_text)\ninds = np.arange(len(en_text))\nnp.random.shuffle(inds)\ntrain_inds = inds[:train_size]\n# Define valid_inds: last valid_size indices\nvalid_inds = inds[train_size: train_size + valid_size]\n# Define tr_en (train EN sentences) and tr_fr (train FR sentences)\ntr_en = [en_text[ti] for ti in train_inds]\ntr_fr = [fr_text[ti] for ti in train_inds]\n# Define v_en (valid EN sentences) and v_fr (valid FR sentences)\nv_en = [en_text[vi] for vi in valid_inds]\nv_fr = [fr_text[vi] for vi in valid_inds]\nprint('Training (EN):\\n', tr_en[:3], '\\nTraining (FR):\\n', tr_fr[:3])\nprint('\\nValid (EN):\\n', v_en[:3], '\\nValid (FR):\\n', v_fr[:3])","outputsMetadata":{"0":{"height":427,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Training (EN):\n"," ['paris is quiet during winter , and it is usually beautiful in november .', 'the united states is usually rainy during winter , but it is never chilly in spring .', 'the mango is his most loved fruit , but the grapefruit is their most loved .'] \n","Training (FR):\n"," [\"paris est calme pendant l' hiver , et il est généralement beau en novembre .\", \"les états-unis est généralement pluvieux pendant l' hiver , mais il est jamais froid au printemps .\", 'la mangue est son fruit le plus cher , mais le pamplemousse est leur plus aimé .']\n","\n","Valid (EN):\n"," ['paris is beautiful during august , and it is never quiet in july .', 'birds are his least favorite animals .', 'china is freezing during summer , and it is rainy in february .'] \n","Valid (FR):\n"," [\"paris est beau au mois d' août , et il est jamais tranquille en juillet .\", 'les oiseaux sont moins ses animaux préférés .', \"chine est le gel pendant l' été , et il pleut en février .\"]\n"]}],"source":["train_size, valid_size = 50000, 5000\n","\n","# Define a sequence of indices from 0 to len(en_text)\n","inds = np.arange(len(en_text))\n","np.random.shuffle(inds)\n","train_inds = inds[:train_size]\n","\n","# Define valid_inds: last valid_size indices\n","valid_inds = inds[train_size: train_size + valid_size]\n","\n","# Define tr_en (train EN sentences) and tr_fr (train FR sentences)\n","tr_en = [en_text[ti] for ti in train_inds]\n","tr_fr = [fr_text[ti] for ti in train_inds]\n","\n","# Define v_en (valid EN sentences) and v_fr (valid FR sentences)\n","v_en = [en_text[vi] for vi in valid_inds]\n","v_fr = [fr_text[vi] for vi in valid_inds]\n","print('Training (EN):\\n', tr_en[:3], '\\nTraining (FR):\\n', tr_fr[:3])\n","print('\\nValid (EN):\\n', v_en[:3], '\\nValid (FR):\\n', v_fr[:3])"]},{"cell_type":"code","execution_count":null,"id":"e13d66ef-be46-49f1-9348-f5ae280fa308","metadata":{"executionCancelledAt":null,"executionTime":3376,"lastExecutedAt":1693990487948,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Convert validation data to onehot\nv_en_x = sents2seqs('source', v_en, onehot=True, reverse=True)\nv_de_y = sents2seqs('target', v_fr, onehot=True)\n\nn_epochs, bsize = 3, 250\nfor ei in range(n_epochs):\n  for i in range(0,train_size,bsize):\n    # Get a single batch of inputs and outputs\n    en_x = sents2seqs('source', tr_en[i:i+bsize], onehot=True, reverse=True)\n    de_y = sents2seqs('target', tr_fr[i:i+bsize], onehot=True)\n    # Train the model on a single batch of data\n    nmt.train_on_batch(en_x, de_y)    \n  # Evaluate the trained model on the validation data\n  res = nmt.evaluate(v_en_x, v_de_y, batch_size=valid_size, verbose=0)\n  print(\"{} => Loss:{}, Val Acc: {}\".format(ei+1,res[0], res[1]*100.0))","outputsMetadata":{"0":{"height":76,"type":"stream"}}},"outputs":[],"source":["# Convert validation data to onehot\n","v_en_x = sents2seqs('source', v_en, onehot=True, reverse=True)\n","v_de_y = sents2seqs('target', v_fr, onehot=True)\n","\n","n_epochs, bsize = 10, 250\n","for ei in range(n_epochs):\n","  for i in range(0,train_size,bsize):\n","    # Get a single batch of inputs and outputs\n","    en_x = sents2seqs('source', tr_en[i:i+bsize], onehot=True, reverse=True)\n","    de_y = sents2seqs('target', tr_fr[i:i+bsize], onehot=True)\n","\n","    # Train the model on a single batch of data\n","    nmt.train_on_batch(en_x, de_y)    \n","    \n","    # Obtain the eval metrics for the training data\n","    res = nmt.evaluate(en_x, de_y, batch_size=bsize, verbose=0)\n","    print(\"{} => Train Loss:{}, Train Acc: {}\".format(ei+1,res[0], res[1]*100.0)) \n","    \n","  # Evaluate the trained model on the validation data\n","  res = nmt.evaluate(v_en_x, v_de_y, batch_size=valid_size, verbose=0)\n","  print(\"{} => Valid Loss:{}, Val Acc: {}\".format(ei+1,res[0], res[1]*100.0))"]},{"cell_type":"code","execution_count":23,"id":"b22110e2-07b3-4d4c-ad83-a66dd521ee69","metadata":{"executionCancelledAt":null,"executionTime":545,"lastExecutedAt":1693990488493,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"\nen_st = ['the united states is sometimes chilly during december , but it is sometimes freezing in june .']\nprint('English: {}'.format(en_st))\n\n# Convert the English sentence to a sequence\nen_seq = sents2seqs('source', en_st, onehot=True, reverse=True)\nprint(en_seq)\n# Predict probabilities of words using en_seq\nfr_pred = nmt.predict(en_seq)\nprint(fr_pred)\n\n# Get the sequence indices (max argument) of fr_pred\nfr_seq = np.argmax(fr_pred, axis=-1)[0]\nprint(fr_seq)\n\n# Convert the sequence of IDs to a sentence and print\nfr_sent = [fr_id2word[i] for i in fr_seq if i != 0]\nprint(\"French (Custom): {}\".format(' '.join(fr_sent)))\nprint(\"French (Google Translate): les etats-unis sont parfois froids en décembre, mais parfois gelés en juin\")","outputsMetadata":{"0":{"height":485,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["English: ['the united states is sometimes chilly during december , but it is sometimes freezing in june .']\n","French (Custom): les états unis est parfois agréable en en mais il est parfois en en\n","French (Google Translate): les etats-unis sont parfois froids en décembre, mais parfois gelés en juin\n"]}],"source":["en_st = ['the united states is sometimes chilly during december , but it is sometimes freezing in june .']\n","print('English: {}'.format(en_st))\n","\n","# Convert the English sentence to a sequence\n","en_seq = sents2seqs('source', en_st, onehot=True, reverse=True)\n","# print(en_seq)\n","\n","# Predict probabilities of words using en_seq\n","fr_pred = nmt.predict(en_seq, verbose=False)\n","# print(fr_pred)\n","\n","# Get the sequence indices (max argument) of fr_pred\n","fr_seq = np.argmax(fr_pred, axis=-1)[0]\n","# print(fr_seq)\n","\n","# Convert the sequence of IDs to a sentence and print\n","fr_id2word = reverse_word_map = dict(map(reversed, fr_tok.word_index.items()))\n","\n","fr_sent = [fr_id2word[i] for i in fr_seq if i != 0]\n","# fr_sent = fr_tok.sequences_to_texts(fr_)\n","print(\"French (Custom): {}\".format(' '.join(fr_sent)))\n","print(\"French (Google Translate): les etats-unis sont parfois froids en décembre, mais parfois gelés en juin\")"]},{"attachments":{},"cell_type":"markdown","id":"65f17bb6","metadata":{},"source":["## 3. Teacher Forcing NMT"]},{"attachments":{},"cell_type":"markdown","id":"50afe3cb","metadata":{},"source":["![Alt text](images/ch41_teacher_force_encoder_decoder.png)"]},{"attachments":{},"cell_type":"markdown","id":"cb3111bc","metadata":{},"source":["### 3.1. Encoder"]},{"cell_type":"code","execution_count":null,"id":"9c2ad0bf","metadata":{},"outputs":[],"source":["# same as before\n","en_inputs = keras.layers.Input(shape=(en_len, en_vocab))\n","en_out, en_state = keras.layers.GRU(hsize, return_state=True)(en_inputs)"]},{"attachments":{},"cell_type":"markdown","id":"2748919d","metadata":{},"source":["### 3.2 Decoder"]},{"cell_type":"code","execution_count":null,"id":"083dd4f9","metadata":{},"outputs":[],"source":["# Decoder input layer\n","de_inputs = keras.layers.Input(shape=(fr_len-1, fr_vocab))\n","de_gru = keras.layers.GRU(hsize, return_sequences=True)\n","de_out = de_gru(de_inputs, initial_state=en_state)\n","\n","# a TimeDistributed Dense softmax layer with fr_vocab nodes\n","de_dense = keras.layers.TimeDistributed(keras.layers.Dense(fr_vocab, activation='softmax'))\n","de_pred = de_dense(de_out)"]},{"attachments":{},"cell_type":"markdown","id":"8b4dec77","metadata":{},"source":["### 3.3. Encoder-Decoder Model"]},{"cell_type":"code","execution_count":null,"id":"64415c93","metadata":{},"outputs":[],"source":["# Define a model\n","nmt_tf = Model(inputs=[en_inputs, de_inputs], outputs=de_pred)\n","\n","# Compile the model with optimizer and loss\n","nmt_tf.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"acc\"])\n","\n","# Print the summary of the model\n","nmt_tf.summary()"]},{"cell_type":"code","execution_count":null,"id":"59233736","metadata":{},"outputs":[],"source":["train_size, valid_size = 800, 200\n","\n","# Define a sequence of indices from 0 to size of en_text\n","inds = np.arange(len(en_text))\n","np.random.shuffle(inds)\n","\n","# Define train_inds as first train_size indices\n","train_inds = inds[:train_size]\n","valid_inds = inds[train_size:train_size+valid_size]\n","\n","# Define tr_en (train EN sentences) and tr_fr (train FR sentences)\n","tr_en = [en_text[ti] for ti in train_inds]\n","tr_fr = [fr_text[ti] for ti in train_inds]\n","\n","# Define v_en (valid EN sentences) and v_fr (valid FR sentences)\n","v_en = [en_text[vi] for vi in valid_inds]\n","v_fr = [fr_text[vi] for vi in valid_inds]\n","\n","print('Training (EN):\\n', tr_en[:3], '\\nTraining (FR):\\n', tr_fr[:3])\n","print('\\nValid (EN):\\n', v_en[:3], '\\nValid (FR):\\n', v_fr[:3])"]},{"cell_type":"code","execution_count":null,"id":"c935b86d","metadata":{},"outputs":[],"source":["n_epochs, bsize = 3, 250\n","\n","for ei in range(n_epochs):\n","  for i in range(0,train_size,bsize):    \n","    en_x = sents2seqs('source', tr_en[i:i+bsize], onehot=True, reverse=True)\n","    de_xy = sents2seqs('target', tr_fr[i:i+bsize], onehot=True)\n","\n","    de_x, de_y = de_xy[:,:-1,:], de_xy[:,1:,:]\n","    nmt_tf.train_on_batch([en_x,de_x], de_y)      \n","\n","  v_en_x = sents2seqs('source', v_en, onehot=True, reverse=True)\n","  v_de_xy = sents2seqs('target', v_en, onehot=True)\n","  v_de_x, v_de_y = v_de_xy[:,:-1,:], v_de_xy[:,1:,:]\n","\n","  # Evaluate the trained model on the validation data\n","  res = nmt_tf.evaluate([v_en_x,v_de_x], v_de_y, batch_size=valid_size, verbose=0)\n","  print(\"{} => Loss:{}, Val Acc: {}\".format(ei+1,res[0], res[1]*100.0))"]},{"attachments":{},"cell_type":"markdown","id":"b7931468","metadata":{},"source":["### 3.4. Inference Model"]},{"attachments":{},"cell_type":"markdown","id":"738a58b5","metadata":{},"source":["The inference model decoder is different to the decoder of the training model. We can't feed the decoder with French words because that is what we want to predict.\n","However, we can use the predicted French word from the previous time step to feed the inference model decoder. \n","\n","Therefore, when you want to generate a translation, the decoder needs to generate one word at a time, while consuming the previous output as an input"]},{"cell_type":"code","execution_count":null,"id":"05f78f56","metadata":{},"outputs":[],"source":["# Define an input layer that accepts a single onehot encoded word\n","de_inputs = keras.layers.Input(shape=(1, fr_vocab))\n","# Define an input to accept the t-1 state\n","de_state_in = keras.layers.Input(shape=(hsize,))\n","de_gru = keras.layers.GRU(hsize, return_state=True)\n","# Get the output and state from the GRU layer\n","de_out, de_state_out = de_gru(de_inputs, initial_state=de_state_in)\n","de_dense = keras.layers.Dense(fr_vocab, activation='softmax')\n","de_pred = de_dense(de_out)\n","\n","# Define a model\n","decoder = Model(inputs=[de_inputs, de_state_in], outputs=[de_pred,de_state_out])\n","print(decoder.summary())"]},{"cell_type":"code","execution_count":null,"id":"1ce8b391","metadata":{},"outputs":[],"source":["# You may load and set wights of the trained model by uncommenting this cell\n","\n","\n","# # Load the weights to the encoder GRU from the trained model\n","# en_gru_w = tr_en_gru.get_weights()\n","# # Set the weights of the encoder GRU of the inference model\n","# en_gru.set_weights(en_gru_w)\n","# # Load and set the weights to the decoder GRU\n","# de_gru.set_weights(tr_de_gru.get_weights())\n","# # Load and set the weights to the decoder Dense\n","# de_dense.set_weights(tr_de_dense.get_weights())"]},{"cell_type":"code","execution_count":null,"id":"14f37a85","metadata":{},"outputs":[],"source":["def probs2word(probs, tok):\n","    wid = np.argmax(probs[0,:], axis=-1)\n","    w = tok.index_word[wid]\n","    return w\n","\n","def word2onehot(tokenizer, word, vocab_size):\n","    de_seq = tokenizer.texts_to_sequences([[word]])\n","    de_onehot = to_categorical(de_seq, num_classes=vocab_size)\n","    de_onehot = np.expand_dims(de_onehot, axis=1)    \n","    return de_onehot"]},{"cell_type":"code","execution_count":null,"id":"1b42521d","metadata":{},"outputs":[],"source":["en_sent = ['the united states is sometimes chilly during december , but it is sometimes freezing in june .']\n","print('English: {}'.format(en_sent))\n","en_seq = sents2seqs('source', en_sent, onehot=True, reverse=True)\n","# Predict the initial decoder state with the encoder\n","de_s_t = encoder.predict(en_seq)\n","de_seq = word2onehot(fr_tok, 'sos', fr_vocab)\n","fr_sent = ''\n","for i in range(fr_len):    \n","  # Predict from the decoder and recursively assign the new state to de_s_t\n","  de_prob, de_s_t = decoder.predict([de_seq, de_s_t])\n","  # Get the word from the probability output using probs2word\n","  de_w = probs2word(de_prob, fr_tok)\n","  # Convert the word to a onehot sequence using word2onehot\n","  de_seq = word2onehot(fr_tok, de_w, fr_vocab)\n","  if de_w == 'eos': break\n","  fr_sent += de_w + ' '\n","print(\"French (Ours): {}\".format(fr_sent))\n","print(\"French (Google Translate): les etats-unis sont parfois froids en décembre, mais parfois gelés en juin\")"]},{"attachments":{},"cell_type":"markdown","id":"edf1307d","metadata":{},"source":["### 3.5. Embedding layer\n","Add embedding layer as an alternative to one-hot encoding for capturing word's meaning."]},{"cell_type":"code","execution_count":null,"id":"19bf34ad","metadata":{},"outputs":[],"source":["# Define an input layer which accepts a sequence of word IDs\n","en_inputs = keras.layers.Input(shape=(en_len,))\n","\n","# Define an Embedding layer which accepts en_inputs\n","en_emb = keras.layers.Embedding(en_vocab, 96, input_length=en_len)(en_inputs)\n","en_out, en_state = keras.layers.GRU(hsize, return_state=True)(en_emb)\n","\n","de_inputs = keras.layers.Input(shape=(fr_len-1,))\n","# Define an Embedding layer which accepts de_inputs\n","de_emb = keras.layers.Embedding(fr_vocab, 96, input_length=fr_len-1)(de_inputs)\n","de_out, _ = keras.layers.GRU(hsize, return_sequences=True, return_state=True)(de_emb, initial_state=en_state)\n","de_pred = keras.layers.TimeDistributed(Dense(fr_vocab, activation='softmax'))(de_out)\n","\n","# Define the Model which accepts encoder/decoder inputs and outputs predictions \n","nmt_emb = Model([en_inputs, de_inputs], de_pred)\n","nmt_emb.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"]},{"cell_type":"code","execution_count":null,"id":"fc1d875d","metadata":{},"outputs":[],"source":["for ei in range(3):\n","  for i in range(0, train_size, bsize):    \n","    en_x = sents2seqs('source', tr_en[i:i+bsize], onehot=False, reverse=True)\n","    # Get a single batch of French sentences with no onehot encoding\n","    de_xy = sents2seqs('target', tr_fr[i:i+bsize], onehot=False)\n","    # Get all words except the last word in that batch\n","    de_x = de_xy[:,:-1]\n","    de_xy_oh = sents2seqs('target', tr_fr[i:i+bsize], onehot=True)\n","    # Get all words except the first from de_xy_oh\n","    de_y = de_xy_oh[:,1:,:]\n","    # Training the model on a single batch of data\n","    nmt_emb.train_on_batch([en_x,de_x], de_y)    \n","    res = nmt_emb.evaluate([en_x, de_x], de_y, batch_size=bsize, verbose=0)\n","    print(\"{} => Loss:{}, Train Acc: {}\".format(ei+1,res[0], res[1]*100.0))"]},{"attachments":{},"cell_type":"markdown","id":"397efef1","metadata":{},"source":["## Acknowledgements\n","This notebook is adopted from Thushan Ganegedara's valuable course on Datacamp. spacial thanks to him for providing slides and resources on understanding machine translation models."]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"market","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"vscode":{"interpreter":{"hash":"fda2fbfebfe2895777435bc02b8b4bfbc61af62d8e2cc33c3e562f5059558a77"}}},"nbformat":4,"nbformat_minor":5}
